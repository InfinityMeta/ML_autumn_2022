{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c511d3",
   "metadata": {},
   "source": [
    "### Data installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd828135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def add_reviews(directory):\n",
    "    reviews = []\n",
    "    with os.scandir(directory) as files:\n",
    "        for file in files:\n",
    "            with open(file, 'r', encoding='utf8') as f:\n",
    "                reviews.append(f.read())\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "train_pos = pd.DataFrame({'review' : add_reviews('./train/pos'), 'target' : 1})\n",
    "train_neg = pd.DataFrame({'review' : add_reviews('./train/neg'), 'target' : 0})\n",
    "\n",
    "test_pos = pd.DataFrame({'review' : add_reviews('./test/pos'), 'target' : 1})\n",
    "test_neg = pd.DataFrame({'review' : add_reviews('./test/neg'), 'target' : 0})\n",
    "\n",
    "df = shuffle(pd.concat([train_pos, train_neg, test_pos, test_neg]))\n",
    "\n",
    "df = df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce5053",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87370967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import re\n",
    "from functools import reduce\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def compose(*functions):\n",
    "      \n",
    "    def comp(f, g):\n",
    "        return lambda x : f(g(x))\n",
    "              \n",
    "    return reduce(comp, functions)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return \"\".join([\" \" if char in string.punctuation else char for char in text])\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return \"\".join([\" \" if char.isdigit() else char for char in text])\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    removewords = stopwords.words(\"english\")\n",
    "    return \" \".join([\"\" if word in removewords else word for word in text.split()])\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "preprocess_text = compose(lower, lemmatize, remove_stopwords, remove_multiple_spaces, remove_numbers, remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3b063",
   "metadata": {},
   "source": [
    "#### Text before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2582a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While some performances were good-Victoria Rowell, Adrienne Barbeau, and the two Italian girlfriends come to mind-the story was lame and derivative, the emphasis on the girlfriend's racial background was handled clumsily at best, and the relatives were mostly portrayed as stereotypes, not as real people. I found myself wincing uncomfortably at many moments that were supposed to be funny. I can hardly comprehend why the local paper here in SF said this was a good movie, and wonder WHO posted the glowing review here on IMDb. Very disappointed in this movie, and mad I actually went to a theatre to see it, based on the faulty connection to Garden State, which is a far funnier, more inventive, and touching movie than this one. I must especially mention the emotional climax in the church, which was so wooden and by-the-numbers that I nearly left, and some in the audience actually DID. THAT was followed by a silly climax at the graveyard, which I saw coming 10 minutes before it happened. I really don't like being misled to spend my money so uselessly.\n"
     ]
    }
   ],
   "source": [
    "text = df.iloc[0]['review']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da0805",
   "metadata": {},
   "source": [
    "#### Text after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d63e4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while performance good victoria rowell adrienne barbeau two italian girlfriend come mind story lame derivative emphasis girlfriend racial background handled clumsily best relative mostly portrayed stereotype real people i found wincing uncomfortably many moment supposed funny i hardly comprehend local paper sf said good movie wonder who posted glowing review imdb very disappointed movie mad i actually went theatre see based faulty connection garden state far funnier inventive touching movie one i must especially mention emotional climax church wooden number i nearly left audience actually did that followed silly climax graveyard i saw coming minute happened i really like misled spend money uselessly\n"
     ]
    }
   ],
   "source": [
    "prep_text = preprocess_text(text)\n",
    "print(prep_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc5f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5de863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, target_train, target_test = train_test_split(df['preprocessed_review'], df['target'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2482c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = df_train.apply(lambda x : x.split())\n",
    "test_w2v = df_test.apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2fd17",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb2431",
   "metadata": {},
   "source": [
    "#### Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312dfcea",
   "metadata": {},
   "source": [
    "#### Transformation of words to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4dad6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9643222, 10628170)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "#CBOW\n",
    "word2vec = Word2Vec(vector_size=100, window=5, min_count=1, sg=0)\n",
    "word2vec.build_vocab(train_w2v)\n",
    "word2vec.train(train_w2v, total_examples=word2vec.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c43410",
   "metadata": {},
   "source": [
    "#### Generation of aggregated sentence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2db827d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "voc = set(word2vec.wv.index_to_key)\n",
    "#changing each word in sentence to vector and applying elementwise mean to get same length \n",
    "X_train_w2v = pd.DataFrame(train_w2v.apply(lambda x : np.array([word2vec.wv[i] for i in x if i in voc]).mean(axis=0)).to_list())\n",
    "X_test_w2v = pd.DataFrame(test_w2v.apply(lambda x : np.array([word2vec.wv[i] for i in x if i in voc]).mean(axis=0)).to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836a769",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a40c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tf_idf = vectorizer.fit_transform(df_train)\n",
    "X_test_tf_idf = vectorizer.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deeee30",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68831a0e",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4602e7cf",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "bdb0a38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "baseline_svm_w2v = svm.SVC()\n",
    "baseline_svm_w2v.fit(X_train_w2v, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9170eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(y_pred, y_true=target_test):\n",
    "    print(f\"\"\"\n",
    "    Accuracy = {round(accuracy_score(y_true, y_pred), 2)} \n",
    "    ROC-AUC = {round(roc_auc_score(y_true, y_pred), 2)} \n",
    "    f1_score = {round(f1_score(y_true, y_pred), 2)} \n",
    "    \"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f0a8c5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.83 \n",
      "    ROC-AUC = 0.83 \n",
      "    f1_score = 0.83 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "y_pred_svm_w2v = baseline_svm_w2v.predict(X_test_w2v)\n",
    "\n",
    "show_metrics(y_pred_svm_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a1908",
   "metadata": {},
   "source": [
    "#### Hyperparameters selection for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b31654b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_svm = {\n",
    "    'C' : [0.5, 0.15, 1.0],\n",
    "    'kernel' : ('poly', 'rbf', 'linear'),\n",
    "}\n",
    "\n",
    "svm_with_search_w2v = GridSearchCV(svm.SVC(), params_svm)\n",
    "svm_with_search_w2v.fit(X_train_w2v, target_train)\n",
    "svm_with_search_w2v.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "496a83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.83 \n",
      "    ROC-AUC = 0.83 \n",
      "    f1_score = 0.83 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "best_svm_w2v = svm.SVC(**svm_with_search_w2v.best_params_)\n",
    "best_svm_w2v.fit(X_train_w2v, target_train)\n",
    "y_pred_svm_best_w2v = best_svm_w2v.predict(X_test_w2v)\n",
    "\n",
    "show_metrics(y_pred_svm_best_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c64d8b",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "caeb7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "baseline_rf_w2v = RandomForestClassifier()\n",
    "baseline_rf_w2v.fit(X_train_w2v, target_train)\n",
    "y_pred_rf_w2v = baseline_rf_w2v.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "97122247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.81 \n",
      "    ROC-AUC = 0.81 \n",
      "    f1_score = 0.81 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "show_metrics(y_pred_rf_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc553ea",
   "metadata": {},
   "source": [
    "#### Hyperparameters selection for Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "02d311e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 100}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rf = {\n",
    "    'n_estimators' : [2, 15, 50, 100],\n",
    "    'max_depth': [None, 2, 8],\n",
    "}\n",
    "\n",
    "rf_with_search_w2v = GridSearchCV(RandomForestClassifier(random_state=42), params_rf)\n",
    "rf_with_search_w2v.fit(X_train_w2v, target_train)\n",
    "rf_with_search_w2v.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bc2c5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_w2v = RandomForestClassifier(**rf_with_search_w2v.best_params_, random_state=42)\n",
    "best_rf_w2v.fit(X_train_w2v, target_train)\n",
    "y_pred_rf_best_w2v = best_rf_w2v.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f2d2ac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.81 \n",
      "    ROC-AUC = 0.81 \n",
      "    f1_score = 0.81 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "show_metrics(y_pred_rf_best_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0fc9c",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af035513",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "faf4cef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.88 \n",
      "    ROC-AUC = 0.88 \n",
      "    f1_score = 0.88 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "baseline_svm_tf_idf = svm.SVC()\n",
    "baseline_svm_tf_idf.fit(X_train_tf_idf, target_train)\n",
    "\n",
    "y_pred_svm_tf_idf = baseline_svm_tf_idf.predict(X_test_tf_idf)\n",
    "\n",
    "show_metrics(y_pred_svm_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d97c55",
   "metadata": {},
   "source": [
    "#### Hyperparameters selection for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c4e8bc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_with_search_tf_idf = GridSearchCV(svm.SVC(), params_svm)\n",
    "svm_with_search_tf_idf.fit(X_train_tf_idf, target_train)\n",
    "svm_with_search_tf_idf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "087e3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.88 \n",
      "    ROC-AUC = 0.88 \n",
      "    f1_score = 0.88 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "best_svm_tf_idf = svm.SVC(**svm_with_search_tf_idf.best_params_)\n",
    "best_svm_tf_idf.fit(X_train_tf_idf, target_train)\n",
    "y_pred_svm_best_tf_idf = best_svm_tf_idf.predict(X_test_tf_idf)\n",
    "\n",
    "show_metrics(y_pred_svm_best_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995ea96",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "63d0c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_rf_tf_idf = RandomForestClassifier()\n",
    "baseline_rf_tf_idf.fit(X_train_tf_idf, target_train)\n",
    "y_pred_rf_tf_idf = baseline_rf_tf_idf.predict(X_test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "35615e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.84 \n",
      "    ROC-AUC = 0.84 \n",
      "    f1_score = 0.84 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "show_metrics(y_pred_rf_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333154ff",
   "metadata": {},
   "source": [
    "#### Hyperparameters selection for Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2ab6e053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 100}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_with_search_tf_idf = GridSearchCV(RandomForestClassifier(random_state=42), params_rf)\n",
    "rf_with_search_tf_idf.fit(X_train_tf_idf, target_train)\n",
    "rf_with_search_tf_idf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f4b5b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_tf_idf = RandomForestClassifier(**rf_with_search_tf_idf.best_params_, random_state=42)\n",
    "best_rf_tf_idf.fit(X_train_tf_idf, target_train)\n",
    "y_pred_rf_best_tf_idf = best_rf_tf_idf.predict(X_test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5fe01cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy = 0.84 \n",
      "    ROC-AUC = 0.84 \n",
      "    f1_score = 0.84 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "show_metrics(y_pred_rf_best_tf_idf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
